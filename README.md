# üíµ D√≥lar Web Scraping com SQLite + Docker

Este projeto realiza a coleta (scraping) da cota√ß√£o atual do **d√≥lar (USD/BRL)** a partir de uma API p√∫blica e salva os dados em um banco de dados **SQLite**, utilizando **Python**. Toda a aplica√ß√£o √© containerizada com **Docker** e orquestrada via **Docker Compose**.

---

## üöÄ Funcionalidades

- Coleta da cota√ß√£o atual do d√≥lar via API da [AwesomeAPI](https://docs.awesomeapi.com.br/api-de-moedas).
- Armazenamento estruturado em banco de dados SQLite (`cotacoes.db`).
- Script automatizado com Docker para rodar em qualquer ambiente.

---

## üß∞ Tecnologias utilizadas

- **Python 3.10**
- **SQLite** (banco de dados leve e embutido)
- **Requests** (para realizar o scraping via API)
- **Docker** e **Docker Compose**

---

## üìÅ Estrutura de pastas

dolar-web-scraping/
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îî‚îÄ‚îÄ scraping.py # Script de scraping + persist√™ncia
‚îÇ
‚îú‚îÄ‚îÄ cotacoes.db # Banco de dados gerado (ap√≥s execu√ß√£o)
‚îú‚îÄ‚îÄ Dockerfile # Imagem do container
‚îú‚îÄ‚îÄ docker-compose.yaml # Orquestra√ß√£o com Docker Compose
‚îú‚îÄ‚îÄ requirements.txt # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md # Este arquivo

yaml
Copy
Edit

---

## ‚öôÔ∏è Como executar

> Pr√©-requisitos: Docker e Docker Compose instalados

1. Clone o reposit√≥rio:

```bash
git clone https://github.com/seu-usuario/dolar-web-scraping.git
cd dolar-web-scraping
Rode o projeto com Docker Compose:

bash
Copy
Edit
docker-compose up --build
Ap√≥s a execu√ß√£o, o arquivo cotacoes.db ser√° criado na raiz do projeto, contendo os dados coletados.

üóÉÔ∏è Estrutura da Tabela
A tabela cotacao_dolar possui os seguintes campos:

id: identificador √∫nico (autoincremento)

moeda: nome da moeda (D√≥lar)

codigo: c√≥digo da moeda (USD)

cotacao: valor atual do d√≥lar

alta: valor m√°ximo no dia

baixa: valor m√≠nimo no dia

data: data da cota√ß√£o

timestamp_coleta: data/hora em que a coleta foi realizada

üß† Objetivo do projeto
Este projeto √© uma aplica√ß√£o simples mas pr√°tica, com foco em:

Demonstrar coleta automatizada de dados (web scraping com API)

Aplicar armazenamento local com banco de dados relacional (SQLite)

Garantir portabilidade com Docker, podendo ser executado em qualquer m√°quina com um √∫nico comando.

